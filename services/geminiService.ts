import { GoogleGenAI, Type } from "@google/genai";
import { GarmentAnalysis, SceneId, PhotoshootImage } from "../types";
import { SCENE_PRESETS } from "../constants";

// Use Gemini 3 Flash for complex reasoning/analysis and Gemini 2.5 Flash for image generation
const ANALYSIS_MODEL = "gemini-3-flash-preview";
const IMAGE_MODEL = "gemini-2.5-flash-image";

const fileToGenerativePart = (base64Data: string, mimeType: string) => {
  const data = base64Data.includes(",") ? base64Data.split(",")[1] : base64Data;
  return {
    inlineData: { data, mimeType: mimeType || "image/jpeg" },
  };
};

const delay = (ms: number) => new Promise((res) => setTimeout(res, ms));

const isRetryableError = (error: any): boolean => {
  const msg = error.message?.toLowerCase() || "";
  return (
    msg.includes("503") ||
    msg.includes("overloaded") ||
    msg.includes("deadline") ||
    msg.includes("resource exhausted") ||
    msg.includes("service unavailable")
  );
};

const handleGeminiError = (error: any) => {
  const msg = error.message?.toLowerCase() || "";
  if (
    msg.includes("not found") ||
    msg.includes("404") ||
    msg.includes("api_key") ||
    msg.includes("invalid")
  ) {
    throw new Error("RESELECT_KEY");
  }
  throw error;
};

/**
 * Deep analysis of garment characteristics, specifically targeting colors and intricate patterns.
 */
export const analyzeGarment = async (
  base64Image: string,
  retryCount = 0,
): Promise<GarmentAnalysis> => {
  try {
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY || "" });
    const imagePart = fileToGenerativePart(base64Image, "image/jpeg");

    const response = await ai.models.generateContent({
      model: ANALYSIS_MODEL,
      contents: {
        parts: [
          {
            text: "AI Fashion Director: Analyze this garment with extreme precision. Identify: 1. Garment Type. 2. Primary Color. 3. List all secondary colors. 4. Fabric texture and weight. 5. Detailed description of unique patterns, prints, mirror work, or embroidery. 6. Overall fit silhouette. Ensure the color and pattern description is exhaustive for high-fidelity replication.",
          },
          imagePart,
        ],
      },
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            garmentType: { type: Type.STRING },
            fabric: { type: Type.STRING },
            colorPalette: {
              type: Type.ARRAY,
              items: { type: Type.STRING },
              description:
                "Primary color MUST be the first index, followed by all secondary accent colors.",
            },
            style: { type: Type.STRING },
            gender: { type: Type.STRING },
            uniquenessLevel: {
              type: Type.STRING,
              description:
                "Exhaustive description of patterns, embroidery details, and unique embellishments.",
            },
          },
          required: [
            "garmentType",
            "fabric",
            "colorPalette",
            "style",
            "gender",
            "uniquenessLevel",
          ],
        },
      },
    });

    const text = response.text || "{}";
    return JSON.parse(text);
  } catch (error: any) {
    if (isRetryableError(error) && retryCount < 3) {
      await delay(1000 * Math.pow(2, retryCount));
      return analyzeGarment(base64Image, retryCount + 1);
    }
    return handleGeminiError(error);
  }
};

/**
 * Generates the photoshoot with a strict visual anchor to ensure 1:1 model and background consistency.
 */
export const generatePhotoshoot = async (
  garmentImage: string,
  analysis: GarmentAnalysis,
  sceneId: SceneId,
  modelPrompt: string,
  poses: string[],
  onProgress: (index: number, total: number, isRetrying?: boolean) => void,
): Promise<PhotoshootImage[]> => {
  const sceneDescription =
    SCENE_PRESETS.find((s) => s.id === sceneId)?.description || "Studio";
  const results: PhotoshootImage[] = [];

  const baseVisualRules = `
        PROFESSIONAL E-COMMERCE PHOTOGRAPHY. 
        GARMENT FIDELITY: Model MUST wear the EXACT ${analysis.garmentType} from the product reference.
        COLOR LOCK: Primary: ${analysis.colorPalette[0]}, Accents: ${analysis.colorPalette.slice(1).join(", ")}.
        PATTERN LOCK: Replicate this EXACT embroidery/pattern: ${analysis.uniquenessLevel}.
        MODEL: ${modelPrompt}.
        SCENE: ${sceneDescription}.
        TECHNICAL: 8k resolution, photorealistic, sharp focus on fabric texture, high-end commercial lighting.
    `;

  // This variable captures the first successful generation to serve as the visual 'source of truth' for identity and background.
  let masterFrameB64: string | null = null;

  for (let i = 0; i < poses.length; i++) {
    let attempts = 0;
    const maxAttempts = 2;
    let success = false;

    while (attempts < maxAttempts && !success) {
      onProgress(i + 1, poses.length, attempts > 0);

      try {
        const ai = new GoogleGenAI({ apiKey: process.env.API_KEY || "" });
        const parts: any[] = [];

        // ALWAYS include the original garment as the primary product reference
        parts.push(fileToGenerativePart(garmentImage, "image/jpeg"));

        // If we have a master frame (from frame 2 onwards), include it to force visual consistency
        if (masterFrameB64) {
          parts.push(fileToGenerativePart(masterFrameB64, "image/png"));
        }

        const frameDirective = masterFrameB64
          ? `
                        STRICT VISUAL CONSISTENCY MANDATE:
                        1. CLONE THE MODEL: You MUST use the EXACT same face, eyes, hair color, and hairstyle from the second reference image. No variations.
                        2. CLONE THE BACKGROUND: The room geometry, wall color, flooring, and lighting direction MUST be identical to the second reference image.
                        3. CLONE THE LIGHTING: Maintain the same shadow softess and light temperature.
                        4. NEW POSE: Maintain all details but change the pose to: ${poses[i]}.
                      `
          : `Establish the definitive model identity and background for this campaign. Ensure the model's outfit matches the garment reference exactly. Pose: ${poses[i]}.`;

        parts.push({ text: `${baseVisualRules}\n${frameDirective}` });

        const response = await ai.models.generateContent({
          model: IMAGE_MODEL,
          contents: { parts },
          config: {
            imageConfig: { aspectRatio: "3:4" },
          },
        });

        const imagePart = response.candidates?.[0]?.content?.parts.find(
          (p) => p.inlineData,
        );
        if (imagePart?.inlineData) {
          const b64 = imagePart.inlineData.data;
          results.push({
            id: `shot-${Date.now()}-${i}`,
            src: `data:image/png;base64,${b64}`,
          });

          // Capture the first shot as the visual anchor for all subsequent poses in this session
          if (!masterFrameB64) {
            masterFrameB64 = b64;
          }
          success = true;
        } else {
          throw new Error("Missing image part in response");
        }
      } catch (error: any) {
        if (isRetryableError(error)) {
          attempts++;
          if (attempts < maxAttempts) {
            await delay(2000);
            continue;
          }
        }
        throw error;
      }
    }
  }
  return results;
};

export const editImage = async (
  base64Image: string,
  prompt: string,
  retryCount = 0,
): Promise<string> => {
  try {
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY || "" });
    const response = await ai.models.generateContent({
      model: IMAGE_MODEL,
      contents: {
        parts: [
          fileToGenerativePart(base64Image, "image/jpeg"),
          {
            text: `Refine this image while maintaining 100% garment and model identity: ${prompt}`,
          },
        ],
      },
      config: {
        imageConfig: { aspectRatio: "3:4" },
      },
    });
    const part = response.candidates?.[0]?.content?.parts.find(
      (p) => p.inlineData,
    );
    if (!part?.inlineData) throw new Error("Edit failed");
    return `data:image/png;base64,${part.inlineData.data}`;
  } catch (error: any) {
    if (isRetryableError(error) && retryCount < 2) {
      await delay(2000);
      return editImage(base64Image, prompt, retryCount + 1);
    }
    return handleGeminiError(error);
  }
};

export const generateImage = async (
  prompt: string,
  retryCount = 0,
): Promise<string> => {
  try {
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY || "" });
    const response = await ai.models.generateContent({
      model: IMAGE_MODEL,
      contents: prompt,
      config: {
        imageConfig: { aspectRatio: "3:4" },
      },
    });
    const part = response.candidates?.[0]?.content?.parts.find(
      (p) => p.inlineData,
    );
    if (!part?.inlineData) throw new Error("Generation failed");
    return `data:image/png;base64,${part.inlineData.data}`;
  } catch (error: any) {
    if (isRetryableError(error) && retryCount < 2) {
      await delay(2000);
      return generateImage(prompt, retryCount + 1);
    }
    return handleGeminiError(error);
  }
};
